{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Example\n",
    "\n",
    "Build a 2-hidden layers fully connected neural network (a.k.a multilayer perceptron) with TensorFlow v2.\n",
    "\n",
    "This example is using a low-level approach to better understand all mechanics behind building neural networks and the training process.\n",
    "\n",
    "- Author: Miguel Tom√°s\n",
    "- Project: https://github.com/aeonSolutions/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Overview\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n",
    "\n",
    "This example is using a file csv dataset.  \n",
    "\n",
    "In this example, each dataset will be converted to float32, normalized to [0, 1] and flattened to a 1-D array of \"num_features\" features \n",
    "\n",
    "More info: https://github.com/aeonSolutions/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualize predictions.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task type to perform\n",
    "taskRunning=\"classification\" # can be: classification / regression\n",
    "\n",
    "# parameters initialization.\n",
    "num_classes = 1 # total classes : number of output results wanted\n",
    "num_features = 0 # data features : number of input variables on the dataset. a value of 0 loads from the dataset bellow\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 1\n",
    "training_steps = 10000\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "\n",
    "#normalization of data\n",
    "normalizeDataValues=True\n",
    "normalizationType= \"max\" # accepts: max, mean\n",
    "normalizationTypeBinary=True\n",
    "\n",
    "# Network parameters.\n",
    "n_hidden_1 = 512 # 1st layer number of neurons.\n",
    "n_hidden_2 = 512 # 2nd layer number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions Data.\n",
    "df_predict_ds=pd.read_csv('./week3_exam_dataset_test.csv')\n",
    "\n",
    "data_predict_x = np.float32(df_predict_ds.values)\n",
    "\n",
    "# Training Data.\n",
    "df_tr=pd.read_csv('./week3_exam_dataset_train.csv')\n",
    "\n",
    "df_tr_raw_y= df_tr['y']\n",
    "\n",
    "df_tr_raw_values_y = df_tr_raw_y.values\n",
    "data_tr_y = np.float32(df_tr_raw_values_y)\n",
    "\n",
    "df_tr_raw_x= df_tr.drop('y',1)\n",
    "if num_features==0:\n",
    "    num_features= df_tr_raw_x.shape[1]\n",
    "else:\n",
    "    rs=\"\"\n",
    "    #TODO: fill possible empty values on the datasets\n",
    "df_tr_raw_values_x = df_tr_raw_x.values\n",
    "data_tr_x = np.float32(df_tr_raw_values_x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_tr_raw_x, df_tr_raw_y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Convert to float32.\n",
    "y_train, y_test = np.array(y_train, np.float32), np.array(y_test, np.float32)\n",
    "\n",
    "# Normalize data values to [0, 1] interval.\n",
    "if normalizeDataValues:\n",
    "    if normalizationType==\"max\":\n",
    "        maxVal_train=np.amax(x_train, axis=0)\n",
    "        maxVal_test=np.amax(x_test, axis=0)\n",
    "        maxVal_pred=np.amax(data_predict_x, axis=0)\n",
    "        maxVal=max(np.amax(maxVal_train, axis=0),np.amax(maxVal_test, axis=0),np.amax(maxVal_pred, axis=0))\n",
    "        if normalizationTypeBinary:\n",
    "            x_train, x_test,data_predict_x = np.where((x_train / maxVal_train)>=0.5,1,0), np.where((x_test / maxVal_test)>=0.5,1,0), np.where((data_predict_x / maxVal_pred)>=0.5,1,0)\n",
    "        else:\n",
    "            x_train, x_test, data_predict_x = x_train / maxVal_train, x_test / maxVal_test, data_predict_x / maxVal_pred\n",
    "    else:\n",
    "        meanVal_test=np.mean(x_test, axis=0)\n",
    "        meanVal_train=np.mean(x_train, axis=0)\n",
    "        meanVal_pred=np.mean(data_predict_x, axis=0)\n",
    "        meanVal=max(np.amax(meanVal_train, axis=0),np.amax(meanVal_test, axis=0),np.amax(meanVal_pred, axis=0))\n",
    "        \n",
    "        if normalizationTypeBinary:\n",
    "            x_train, x_test,data_predict_x = np.where((x_train / meanVal_train)>=0.5,1,0), np.where((x_test / meanVal_test)>=0.5,1,0), np.where((data_predict_x / meanVal_pred)>=0.5,1,0)\n",
    "        else:\n",
    "            x_train, x_test, data_predict_x = x_train / meanVal_train, x_test / meanVal_test, data_predict_x / meanVal_pred\n",
    "\n",
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF Model.\n",
    "class NeuralNet(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc1 = layers.Dense(n_hidden_1, activation=tf.nn.relu)\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc2 = layers.Dense(n_hidden_2, activation=tf.nn.relu)\n",
    "        # Second fully-connecter hidden layer.\n",
    "        if (taskRunning==\"classification\"):\n",
    "            self.out = layers.Dense(num_classes+1)\n",
    "        else:\n",
    "            self.out = layers.Dense(num_classes)\n",
    "            \n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        if not is_training:\n",
    "            # tf cross entropy expect logits without softmax, so only\n",
    "            # apply softmax when not training.\n",
    "            x = tf.nn.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Build neural network model.\n",
    "neural_net = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss.\n",
    "# Note that this will apply 'softmax' to the logits.\n",
    "def cross_entropy_loss(x, y):\n",
    "    # Convert labels to int 64 for tf cross-entropy function.\n",
    "    y = tf.cast(y, tf.int32)\n",
    "    if (taskRunning==\"regression\"):\n",
    "        loss=tf.keras.losses.binary_crossentropy(y, x)\n",
    "    else:    \n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
    "    # Apply softmax to logits and compute cross-entropy.\n",
    "    # Average loss across the batch.\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracyAvg(y_pred):\n",
    "    print(y_pred.numpy().shape)\n",
    "    \n",
    "    #convert to 1D array\n",
    "    y_pred_1d_array= y_pred.ravel()\n",
    "    \n",
    "    accCalc= np.full(y_pred_1d_array.shape, 0)\n",
    "    delta=np.amax(real_y_1d_array)-np.amin(real_y_1d_array)\n",
    "    \n",
    "    for i in range(len(y_pred_1d_array)):\n",
    "        accCalc[i]= abs(delta-y_pred_1d_array[i] - real_y_1d_array[i])\n",
    "    \n",
    "    return accCalc\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass.\n",
    "        pred = neural_net(x, is_training=True)\n",
    "        # Compute loss.\n",
    "        loss = cross_entropy_loss(pred, y)\n",
    "        \n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = neural_net.trainable_variables\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "def live_plot(steps, accuracy, figsize=(7,5), title=''):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.xlim(0, training_steps)\n",
    "    plt.ylim(0, 100)\n",
    "    steps= [float(i) for i in steps]\n",
    "    accuracy= [float(i) for i in accuracy]\n",
    "    \n",
    "    m=0\n",
    "    if len(steps) > 1:\n",
    "        plt.scatter(steps,accuracy, label='accuracy', color='k') \n",
    "        m, b = np.polyfit(steps, accuracy, 1)\n",
    "        plt.plot(steps, [x * m for x in steps] + b)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy %')\n",
    "    #plt.legend(loc='center left') # the plot evolves to the right\n",
    "    plt.show();\n",
    "    return m\n",
    "\n",
    "def ETC(start, steps):\n",
    "    time_elapsed = datetime.now() - start\n",
    "    eta= (training_steps-steps) / display_step * time_elapsed\n",
    "    #avgString = str(avg).split(\".\")[0]\n",
    "    \n",
    "    hours= int(eta.seconds/3600)\n",
    "    minutes= int((eta.seconds/60)-hours*60)\n",
    "    seconds = int(eta.seconds - minutes*60 -hours*3600)\n",
    "    return \"%sh, %s min and %s sec\" % (hours, minutes, seconds)\n",
    "\n",
    "def elapsedTime(elapsed):\n",
    "    hours= int(elapsed.seconds/3600)\n",
    "    minutes= int((elapsed.seconds/60)-hours*60)\n",
    "    seconds = int(elapsed.seconds - minutes*60 -hours*3600)\n",
    "    return \"%sh, %s min and %s sec\" % (hours, minutes, seconds)\n",
    "\n",
    "def progress(percent=0, width=30):\n",
    "    left = width * percent // 100\n",
    "    right = width - left\n",
    "    print('\\r[', '#' * left, ' ' * right, ']',\n",
    "          f' {percent:.0f}%\\n',\n",
    "          sep='', end='', flush=True)\n",
    "    \n",
    "def measureSkewness(series):    \n",
    "    result=\"\"\n",
    "    \n",
    "    if (series.skew() > 1 or series.skew() < -1):\n",
    "        result=\"Highly skewed distribution\"\n",
    "    elif((0.5 < series.skew() < 1) or (-1 < series.skew() < -0.5)):\n",
    "        result=\"Moderately skewed distribution\"\n",
    "    elif(-0.5 < series.skew() < 0.5):\n",
    "        result=\"Approximately symmetric distribution\"\n",
    "    result = result +\" ( \" +str(round(series.skew(),2))+\" )\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##############################] 100%\n",
      "\n",
      "================= Iteration Stats ================\n",
      "                   step: 10000 of 10000\n",
      "                   loss: 0.522784\n",
      "\n",
      "          step accuracy: 70.00 %\n",
      "                    AVG: 77.28 %\n",
      "                   Best: 90.00 %\n",
      "\n",
      "            Trend slope: -0.000\n",
      "         MAD Dispersion: nan\n",
      "               Skewness: Approximately symmetric distribution ( -0.12 )\n",
      "\n",
      "================= Time           ================\n",
      "                Elapsed: 0h, 2 min and 12 sec\n",
      "                    ETC: 0h, 0 min and 0 sec\n",
      "\n",
      "================= Network Setup  ================\n",
      "      number of classes: 1\n",
      "     number of features: 14\n",
      "          learning rate: 1\n",
      "         training steps: 10000\n",
      "             batch size: 100\n",
      "1st layer n. of neurons: 512\n",
      "2st layer n. of neurons: 512\n",
      "        Normalized data: True, type: max, Discrete Binary 0/1\n",
      "\n",
      "Trainning Analysis Finished. Start testing test dataset...\n",
      "\n",
      "Accuracy of highest score in prediction dataset\n",
      "         Test Accuracy: 77.00 %\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "avgCounter=0\n",
    "avg=0.0\n",
    "\n",
    "steps=[]\n",
    "accuracyValue=[]\n",
    "\n",
    "start_time = datetime.now()\n",
    "totalStartTime=start_time\n",
    "    \n",
    "live_plot([0], [0])\n",
    "print(\"analysis started. Waiting for preliminary data. One moment please...\")\n",
    "progress(0) \n",
    "\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization(batch_x, batch_y)\n",
    "        \n",
    "    if step % display_step == 0 or step==training_steps:\n",
    "        pred = neural_net(batch_x, is_training=True)\n",
    "        loss = cross_entropy_loss(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        avgCounter+=1\n",
    "        avg+=acc*100\n",
    "        \n",
    "        steps.append(step)\n",
    "        accuracyValue.append(acc*100)\n",
    "        trendSlope= live_plot(steps, accuracyValue)\n",
    "        totalTime =datetime.now()- totalStartTime\n",
    "        \n",
    "        stats=pd.Series(accuracyValue)\n",
    "        \n",
    "        if int(step/training_steps*100)<100:\n",
    "            print(\"Running...\")\n",
    "        progress(int(step/training_steps*100)) \n",
    "        print(\"\")\n",
    "        print(\"================= Iteration Stats ================\")\n",
    "        print(\"                   step: %i of %i\" % (step,training_steps))\n",
    "        print(\"                   loss: %f\" % loss)\n",
    "        print(\"\")\n",
    "        print(\"          step accuracy: %.2f %%\" %  (acc*100))\n",
    "        print(\"                    AVG: %.2f %%\" % (avg/avgCounter))\n",
    "        print(\"                   Best: %.2f %%\" % (np.max(accuracyValue)))\n",
    "        print(\"\")\n",
    "        print(\"            Trend slope: %.3f\" % (trendSlope))\n",
    "        print(\"         MAD Dispersion: \" + str(stats.mad()))\n",
    "        print(\"               Skewness: \" + measureSkewness(stats))\n",
    "        print(\"\")\n",
    "        print(\"================= Time           ================\")\n",
    "        print(\"                Elapsed: \" + elapsedTime(totalTime))\n",
    "        print(\"                    ETC: \" + ETC(start_time,step))\n",
    "        print(\"\")\n",
    "        print(\"================= Network Setup  ================\")\n",
    "        print(\"      number of classes: \"+ str(num_classes))\n",
    "        print(\"     number of features: \"+ str(num_features)) \n",
    "\n",
    "        print(\"          learning rate: \"+ str(learning_rate))\n",
    "        print(\"         training steps: \"+ str(training_steps))\n",
    "        print(\"             batch size: \"+ str(batch_size))\n",
    "\n",
    "        print(\"1st layer n. of neurons: \"+ str(n_hidden_1 ))\n",
    "        print(\"2st layer n. of neurons: \"+ str(n_hidden_2))\n",
    "        print(\"        Normalized data: \" + (\"True\" if normalizeDataValues else \"False\") +\", type: \" + normalizationType +\", \" +(\"Discrete Binary 0/1\" if normalizationTypeBinary else \"Continuous range [0,1]\"))\n",
    "\n",
    "        start_time = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Trainning Analysis Finished. Start testing test dataset...\")\n",
    "print(\"\")\n",
    "run_test = neural_net(x_test, is_training=False)\n",
    "print(\"Accuracy of highest score in prediction dataset\")\n",
    "print(\"         Test Accuracy: %.2f %%\" % (tf.math.round(100*accuracy(run_test, y_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution of values:\n",
      "      equal to 1: 0.0%\n",
      "      equal to 0: 100.0%\n",
      "\n",
      "checking answers:\n",
      "none of the answers matches the output\n",
      "Answer starts with '0 0 1', matches [80]: 79.21% of values\n",
      "Answer starts with '1 0 1', matches [55]: 54.46% of values\n",
      "Answer starts with '1 1 0', matches [21]: 20.79% of values\n",
      "Answer starts with '2 1 0', matches [15]: 14.85% of values\n"
     ]
    }
   ],
   "source": [
    "def calStats(output, answer):\n",
    "    num_matches= np.sum(output[:min(len(output), len(answer))] == answer[:min(len(output), len(answer))])\n",
    "    percentage =round((num_matches / min(len(output), answer.shape[1]))*100,2)\n",
    "    return num_matches, percentage\n",
    "\n",
    "run_prediction = neural_net(data_predict_x, is_training=False)\n",
    "output_pre=np.round(run_prediction.numpy(),0)\n",
    "\n",
    "#assessing output value with its probability \n",
    "ouput = np.empty(shape=(output_pre.shape[0],1))\n",
    "for i in range(output_pre.shape[0]):\n",
    "    if ((output_pre[i][0]==1 and output_pre[i][1]==0) or (output_pre[i][0]==0 and output_pre[i][1]==1)):\n",
    "        res[i][0]=0\n",
    "    elif((output_pre[i][0]==1 and output_pre[i][1]==1) or (output_pre[i][0]==0 and output_pre[i][1]==0)):\n",
    "        res[i][0]=1\n",
    "\n",
    "print(\"distribution of values:\")\n",
    "print(\"      equal to 1: \" + str( round(np.sum(output==1)/output.shape[0]*100,1) )+\"%\")\n",
    "print(\"      equal to 0: \" + str( round(np.sum(output==0)/output.shape[0]*100,1) )+\"%\")\n",
    "\n",
    "#checking answers\n",
    "answer1=np.array([[0,0,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,1,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1]])\n",
    "answer2=np.array([[1,0,1,1,1,1,0,0,1,0,0,1,0,0,1,1,0,1,0,0,0,0,1,0,1,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,0,0,0,1,0,1,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,1,1,0,0,1,0,1,0,1,0,1,0,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1]])\n",
    "answer3=np.array([[1,1,0,1,0,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,1,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,0,1,1,0]])\n",
    "answer4=np.array([[2,1,0,2,0,1,0,2,1,2,1,2,1,1,2,1,1,1,1,2,0,1,3,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,3,1,1,1,1,1,2,1,0,1,1,1,0,1,1,2,1,3,1,1,1,0,0,1,1,2,1,1,1,1,1,1,1,2,1,2,0,1,1,2,1,0,0,2,1,1,1,2,0,1,1,1,1,1,2,1,1,0,1,1,0,3,1,0]])\n",
    "\n",
    "print(\"\")\n",
    "print(\"checking answers:\")\n",
    "\n",
    "if (output==answer1).all():\n",
    "    print(\"answwer starts with '0 0 1'\")\n",
    "elif (output==answer2).all():\n",
    "    print(\"answwer starts with '1 0 1'\")\n",
    "elif (output==answer3).all():\n",
    "    print(\"answwer starts with '1 1 0'\")\n",
    "elif (output==answer4).all():\n",
    "    print(\"answwer starts with '2 1 0'\")\n",
    "else:\n",
    "    print(\"none of the answers matches the output\")\n",
    "    num_matches, percentage= calStats(output, answer1)\n",
    "    print (\"Answer starts with '0 0 1', matches [\"+ str(num_matches)+\"]: \"+ str(percentage) +\"% of values\")\n",
    "    num_matches, percentage= calStats(output, answer2)\n",
    "    print (\"Answer starts with '1 0 1', matches [\"+ str(num_matches)+\"]: \"+ str(percentage) +\"% of values\")\n",
    "    num_matches, percentage= calStats(output, answer3)\n",
    "    print (\"Answer starts with '1 1 0', matches [\"+ str(num_matches)+\"]: \"+ str(percentage) +\"% of values\")\n",
    "    num_matches, percentage= calStats(output, answer4)\n",
    "    print (\"Answer starts with '2 1 0', matches [\"+ str(num_matches)+\"]: \"+ str(percentage) +\"% of values\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Author: Miguel Tom√°s \n",
    "\n",
    " License: Creative Commons \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
